{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nick/anaconda3/lib/python3.7/site-packages/setuptools/distutils_patch.py:26: UserWarning: Distutils was imported before Setuptools. This usage is discouraged and may exhibit undesirable behaviors or errors. Please use Setuptools' objects directly or at least import Setuptools first.\n",
      "  \"Distutils was imported before Setuptools. This usage is discouraged \"\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from random import sample\n",
    "import datetime\n",
    "import numpy as np\n",
    "\n",
    "from ipywidgets import IntProgress\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "import girder_client\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torchmetrics\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from pytorch_unet import UNet, UNet_rect_kernels\n",
    "from dataset_loader import DataAugmentor\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Save timestamp: 2021-08-05_16-21-43\n"
     ]
    }
   ],
   "source": [
    "this_notebook_name = \"PyTorchSagittalSpineSegmentationStudy-RectangularKernels\"\n",
    "\n",
    "# Update this folder name for your computer\n",
    "\n",
    "local_data_folder = r\"/home/nick/dev/SaggitalSpineSegmentation_Data\"\n",
    "overwrite_existing_data_files = False\n",
    "\n",
    "# All results and output will be archived with this timestamp\n",
    "\n",
    "save_timestamp = datetime.datetime.now().strftime('%Y-%m-%d_%H-%M-%S')\n",
    "print(\"Save timestamp: {}\".format(save_timestamp))\n",
    "\n",
    "# Learning parameters\n",
    "ultrasound_size = 128\n",
    "num_classes = 2\n",
    "num_epochs = 500 # was 500\n",
    "batch_size = 128\n",
    "max_learning_rate = 0.025\n",
    "min_learning_rate = 0.00005\n",
    "\n",
    "# I will use exponential learning rate decay, not linear\n",
    "# need to solve the system of equations:\n",
    "\n",
    "# x**y = max_learning_rate\n",
    "# x**(num_epochs + y) = min_learning_rate\n",
    "\n",
    "# Here, x is the decay factor we want\n",
    "# solving analytically by hand bc I am a math major (and sympy failed):\n",
    "\n",
    "# y*ln(x) = ln(max_learning_rate)\n",
    "# (num_epochs + y) * ln(x) = ln(min_learning_rate)\n",
    "# (num_epochs + (ln(max_learning_rate)/ln(x)))*ln(x) = ln(min_learning_rate)\n",
    "# ln(x)*num_epochs + ln(max_learning_rate) = ln(min_learning_rate)\n",
    "# ln(x) = (ln(min_learning_rate) - ln(max_learning_rate))/num_epochs\n",
    "# ln(x) = ln( (min_learning_rate / max_learning_rate)**(1/num_epochs) )\n",
    "# x = (min_learning_rate / max_learning_rate)**(1/num_epochs)\n",
    "\n",
    "learning_rate_decay = (min_learning_rate / max_learning_rate)**(1/num_epochs)\n",
    "\n",
    "regularization_rate = 0.001\n",
    "filter_multiplier = 10\n",
    "WCE_weights = np.array([0.1, 0.9])\n",
    "\n",
    "# Training data augmentation parameters\n",
    "\n",
    "max_shift_factor = 0.12\n",
    "max_rotation_angle = 10\n",
    "max_zoom_factor = 1.1\n",
    "min_zoom_factor = 0.8\n",
    "\n",
    "# Evaluation parameters\n",
    "\n",
    "acceptable_margin_mm = 1.0\n",
    "mm_per_pixel = 1.0\n",
    "\n",
    "roc_thresholds = [0.9, 0.8, 0.7, 0.65, 0.6, 0.55, 0.5, 0.45, 0.4, 0.35, 0.3, 0.25, 0.2, 0.15, 0.1,\n",
    "                  0.08, 0.06, 0.04, 0.02, 0.01,\n",
    "                  0.008, 0.006, 0.004, 0.002, 0.001]\n",
    "\n",
    "limit_validation_rounds = -1\n",
    "\n",
    "# Uncomment for faster debugging\n",
    "\n",
    "# roc_thresholds = [0.8, 0.6, 0.4, 0.2, 0.1, 0.01]\n",
    "# limit_validation_rounds = 1\n",
    "# num_epochs = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define what data to download\n",
    "\n",
    "girder_api_url = \"https://pocus.cs.queensu.ca/api/v1\"\n",
    "\n",
    "training_ultrasound_ids = [\n",
    "    \"5da9e5c0d9e6a3be02d012b4\",\n",
    "    \"5da9e5c7d9e6a3be02d012c6\",\n",
    "    \"5da9e5c2d9e6a3be02d012b7\",\n",
    "    \"5da9e5c3d9e6a3be02d012ba\",\n",
    "    \"5da9e5c8d9e6a3be02d012c9\",\n",
    "    \"5da9e5c5d9e6a3be02d012c0\",\n",
    "    \"5da9e5c6d9e6a3be02d012c3\",\n",
    "    \"5da9e5c4d9e6a3be02d012bd\"\n",
    "]\n",
    "\n",
    "training_ultrasound_filenames = [\n",
    "    \"q000_ultrasound.npy\",\n",
    "    \"q001_ultrasound.npy\",\n",
    "    \"q002_ultrasound.npy\",\n",
    "    \"q003_ultrasound.npy\",\n",
    "    \"q004_ultrasound.npy\",\n",
    "    \"q005_ultrasound.npy\",\n",
    "    \"q006_ultrasound.npy\",\n",
    "    \"q007_ultrasound.npy\"\n",
    "]\n",
    "\n",
    "training_segmentation_ids = [\n",
    "    \"5da9e5c8d9e6a3be02d012cc\",\n",
    "    \"5da9e5ccd9e6a3be02d012de\",\n",
    "    \"5da9e5c9d9e6a3be02d012cf\",\n",
    "    \"5da9e5cad9e6a3be02d012d2\",\n",
    "    \"5da9e5cdd9e6a3be02d012e1\",\n",
    "    \"5da9e5cbd9e6a3be02d012d8\",\n",
    "    \"5da9e5cbd9e6a3be02d012db\",\n",
    "    \"5da9e5cad9e6a3be02d012d5\"\n",
    "]\n",
    "\n",
    "training_segmentation_filenames = [\n",
    "    \"q000_segmentation.npy\",\n",
    "    \"q001_segmentation.npy\",\n",
    "    \"q002_segmentation.npy\",\n",
    "    \"q003_segmentation.npy\",\n",
    "    \"q004_segmentation.npy\",\n",
    "    \"q005_segmentation.npy\",\n",
    "    \"q006_segmentation.npy\",\n",
    "    \"q007_segmentation.npy\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These subfolders will be created/populated in the data folder\n",
    "\n",
    "data_arrays_folder    = \"DataArrays\"\n",
    "notebooks_save_folder = \"SavedNotebooks\"\n",
    "results_save_folder   = \"SavedResults\"\n",
    "models_save_folder    = \"SavedModels\"\n",
    "val_data_folder       = \"PredictionsValidation\"\n",
    "\n",
    "data_arrays_fullpath = os.path.join(local_data_folder, data_arrays_folder)\n",
    "notebooks_save_fullpath = os.path.join(local_data_folder, notebooks_save_folder)\n",
    "results_save_fullpath = os.path.join(local_data_folder, results_save_folder)\n",
    "models_save_fullpath = os.path.join(local_data_folder, models_save_folder)\n",
    "val_data_fullpath = os.path.join(local_data_folder, val_data_folder)\n",
    "\n",
    "if not os.path.exists(data_arrays_fullpath):\n",
    "    os.makedirs(data_arrays_fullpath)\n",
    "    print(\"Created folder: {}\".format(data_arrays_fullpath))\n",
    "\n",
    "if not os.path.exists(notebooks_save_fullpath):\n",
    "    os.makedirs(notebooks_save_fullpath)\n",
    "    print(\"Created folder: {}\".format(notebooks_save_fullpath))\n",
    "\n",
    "if not os.path.exists(results_save_fullpath):\n",
    "    os.makedirs(results_save_fullpath)\n",
    "    print(\"Created folder: {}\".format(results_save_fullpath))\n",
    "\n",
    "if not os.path.exists(models_save_fullpath):\n",
    "    os.makedirs(models_save_fullpath)\n",
    "    print(\"Created folder: {}\".format(models_save_fullpath))\n",
    "\n",
    "if not os.path.exists(val_data_fullpath):\n",
    "    os.makedirs(val_data_fullpath)\n",
    "    print(\"Created folder: {}\".format(val_data_fullpath))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading training files ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "795dc50360c64401a5fa2cd47e226724",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntProgress(value=0, max=16)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total download time: 0:00:00.013526\n"
     ]
    }
   ],
   "source": [
    "# Download data from Girder\n",
    "\n",
    "time_download_start = datetime.datetime.now()\n",
    "\n",
    "print(\"Downloading training files ...\")\n",
    "\n",
    "# Setting up number of validation rounds\n",
    "\n",
    "n_files = len(training_ultrasound_ids)\n",
    "if limit_validation_rounds > 0:\n",
    "    num_validation_rounds = min(n_files, limit_validation_rounds)\n",
    "else:\n",
    "    num_validation_rounds = n_files\n",
    "\n",
    "# Preparing progress bar\n",
    "\n",
    "f = IntProgress(min=0, max=n_files*2)\n",
    "display(f)\n",
    "\n",
    "# Downloading files\n",
    "\n",
    "gclient = girder_client.GirderClient(apiUrl=girder_api_url)\n",
    "\n",
    "for i in range(n_files):\n",
    "    ultrasound_fullname = os.path.join(data_arrays_fullpath, training_ultrasound_filenames[i])\n",
    "    if not os.path.exists(ultrasound_fullname) or overwrite_existing_data_files:\n",
    "        print(\"Downloading {}...\".format(ultrasound_fullname))\n",
    "        gclient.downloadFile(training_ultrasound_ids[i], ultrasound_fullname)\n",
    "    f.value = i * 2 + 1\n",
    "    \n",
    "    segmentation_fullname = os.path.join(data_arrays_fullpath, training_segmentation_filenames[i])\n",
    "    if not os.path.exists(segmentation_fullname) or overwrite_existing_data_files:\n",
    "        print(\"Downloading {}...\".format(segmentation_fullname))\n",
    "        gclient.downloadFile(training_segmentation_ids[i], segmentation_fullname)\n",
    "    f.value = i * 2 + 2\n",
    "\n",
    "time_download_stop = datetime.datetime.now()\n",
    "print(\"\\nTotal download time: {}\".format(time_download_stop - time_download_start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2df37cb9006345b2a132797d5ee87c35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntProgress(value=0, max=16)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total time to load from files: 0:00:00.151781\n"
     ]
    }
   ],
   "source": [
    "# Read data into torch tensors in channel-first format, dtype float\n",
    "\n",
    "ultrasound_tensors = []\n",
    "segmentation_tensors = []\n",
    "\n",
    "f = IntProgress(min=0, max=n_files * 2)\n",
    "display(f)\n",
    "\n",
    "time_start = datetime.datetime.now()\n",
    "\n",
    "for i in range(n_files):\n",
    "    ultrasound_fullname = os.path.join(data_arrays_fullpath, training_ultrasound_filenames[i])\n",
    "    segmentation_fullname = os.path.join(data_arrays_fullpath, training_segmentation_filenames[i])\n",
    "\n",
    "    ultrasound_data = np.load(ultrasound_fullname)\n",
    "    ultrasound_data = torch.Tensor(ultrasound_data).permute(0,3,1,2).float()\n",
    "    f.value = i * 2 + 1\n",
    "    \n",
    "    segmentation_data = np.load(segmentation_fullname)\n",
    "    segmentation_data = torch.Tensor(segmentation_data).long().permute(0,3,1,2)\n",
    "\n",
    "    f.value = i * 2 + 2\n",
    "    \n",
    "    ultrasound_tensors.append(ultrasound_data)\n",
    "    segmentation_tensors.append(segmentation_data)\n",
    "\n",
    "time_stop = datetime.datetime.now()\n",
    "print(\"\\nTotal time to load from files: {}\".format(time_stop - time_start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: GeForce RTX 2060 SUPER\n"
     ]
    }
   ],
   "source": [
    "# Use cuda GPU if available\n",
    "\n",
    "device_name = \" \"\n",
    "if torch.cuda.is_available():\n",
    "    device_name = torch.cuda.get_device_name(torch.cuda.current_device())\n",
    "else:\n",
    "    device_name = 'CPU'\n",
    "    \n",
    "print('Using device:', device_name)\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timestamp for saved files: 2021-08-05_16-21-43\n",
      "\n",
      "Training parameters\n",
      "Number of epochs:    500\n",
      "Step size maximum:   0.025\n",
      "Step size decay:     0.9876477074806245\n",
      "Batch size:          128\n",
      "Regularization rate: 0.001\n",
      "\n",
      "Saving validation predictions in: /home/nick/dev/SaggitalSpineSegmentation_Data/PredictionsValidation\n",
      "Saving models in:                 /home/nick/dev/SaggitalSpineSegmentation_Data/SavedModels\n",
      "\n",
      "*** Leave-one-out round # 0\n",
      "\n",
      "Training on 2767 images, validating on 523 images...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db25ab58d43449daab0f1349d4f7efa5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntProgress(value=0, max=500)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Metrics at the end of training\n",
      "  val loss:      0.03631035054732919\n",
      "  val_dice:      0.9922396421432496\n",
      "  Training time: 0:24:14.269008\n",
      "/home/nick/dev/SaggitalSpineSegmentation_Data/SavedModels/PyTorchSagittalSpineSegmentationStudy-RectangularKernels_model-0_2021-08-05_16-21-43.msd\n",
      "\n",
      "Total round time:  0:24:14.468220\n",
      "\n",
      "\n",
      "*** Leave-one-out round # 1\n",
      "\n",
      "Training on 2935 images, validating on 355 images...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "758410fd33304cbab6b0d95f10b0d36b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntProgress(value=0, max=500)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Metrics at the end of training\n",
      "  val loss:      0.06484642654237613\n",
      "  val_dice:      0.9968359470367432\n",
      "  Training time: 0:24:12.729564\n",
      "/home/nick/dev/SaggitalSpineSegmentation_Data/SavedModels/PyTorchSagittalSpineSegmentationStudy-RectangularKernels_model-1_2021-08-05_16-21-43.msd\n",
      "\n",
      "Total round time:  0:24:12.863739\n",
      "\n",
      "\n",
      "*** Leave-one-out round # 2\n",
      "\n",
      "Training on 2813 images, validating on 477 images...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd455f2ade234b169134d0c968ed4c6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntProgress(value=0, max=500)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Metrics at the end of training\n",
      "  val loss:      0.037364095152673985\n",
      "  val_dice:      0.9936337471008301\n",
      "  Training time: 0:24:11.526145\n",
      "/home/nick/dev/SaggitalSpineSegmentation_Data/SavedModels/PyTorchSagittalSpineSegmentationStudy-RectangularKernels_model-2_2021-08-05_16-21-43.msd\n",
      "\n",
      "Total round time:  0:24:11.705876\n",
      "\n",
      "\n",
      "*** Leave-one-out round # 3\n",
      "\n",
      "Training on 2837 images, validating on 453 images...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dccb2e57ba0a42adbae2121a0e12eca1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntProgress(value=0, max=500)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Metrics at the end of training\n",
      "  val loss:      0.050368495071697446\n",
      "  val_dice:      0.9924143105745316\n",
      "  Training time: 0:24:19.502991\n",
      "/home/nick/dev/SaggitalSpineSegmentation_Data/SavedModels/PyTorchSagittalSpineSegmentationStudy-RectangularKernels_model-3_2021-08-05_16-21-43.msd\n",
      "\n",
      "Total round time:  0:24:19.679162\n",
      "\n",
      "\n",
      "*** Leave-one-out round # 4\n",
      "\n",
      "Training on 3001 images, validating on 289 images...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22652c596aa548189112272495c8eb47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntProgress(value=0, max=500)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Metrics at the end of training\n",
      "  val loss:      0.03196355169413412\n",
      "  val_dice:      0.9937101403872172\n",
      "  Training time: 0:24:27.140920\n",
      "/home/nick/dev/SaggitalSpineSegmentation_Data/SavedModels/PyTorchSagittalSpineSegmentationStudy-RectangularKernels_model-4_2021-08-05_16-21-43.msd\n",
      "\n",
      "Total round time:  0:24:27.255095\n",
      "\n",
      "\n",
      "*** Leave-one-out round # 5\n",
      "\n",
      "Training on 2903 images, validating on 387 images...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85ae5d79228d473cb91f76209ae3b943",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntProgress(value=0, max=500)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Metrics at the end of training\n",
      "  val loss:      0.04322067592341154\n",
      "  val_dice:      0.9911937266588211\n",
      "  Training time: 0:24:26.872959\n",
      "/home/nick/dev/SaggitalSpineSegmentation_Data/SavedModels/PyTorchSagittalSpineSegmentationStudy-RectangularKernels_model-5_2021-08-05_16-21-43.msd\n",
      "\n",
      "Total round time:  0:24:27.021587\n",
      "\n",
      "\n",
      "*** Leave-one-out round # 6\n",
      "\n",
      "Training on 2930 images, validating on 360 images...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5569b0b67424432b81f6950f96ec42ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntProgress(value=0, max=500)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Metrics at the end of training\n",
      "  val loss:      0.046813008437554045\n",
      "  val_dice:      0.9900844097137451\n",
      "  Training time: 0:24:23.108387\n",
      "/home/nick/dev/SaggitalSpineSegmentation_Data/SavedModels/PyTorchSagittalSpineSegmentationStudy-RectangularKernels_model-6_2021-08-05_16-21-43.msd\n",
      "\n",
      "Total round time:  0:24:23.248230\n",
      "\n",
      "\n",
      "*** Leave-one-out round # 7\n",
      "\n",
      "Training on 2844 images, validating on 446 images...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60a1e42a3a31414c93d3b88a2b3d1625",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntProgress(value=0, max=500)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Metrics at the end of training\n",
      "  val loss:      0.04553091761576755\n",
      "  val_dice:      0.9925331622362137\n",
      "  Training time: 0:24:23.825587\n",
      "/home/nick/dev/SaggitalSpineSegmentation_Data/SavedModels/PyTorchSagittalSpineSegmentationStudy-RectangularKernels_model-7_2021-08-05_16-21-43.msd\n",
      "\n",
      "Total round time:  0:24:24.006074\n",
      "\n",
      "\n",
      "Total training time:   3:14:46.909480\n"
     ]
    }
   ],
   "source": [
    "# This is where all the training gets done\n",
    "\n",
    "# Print training parameters, to archive them together with the notebook output.\n",
    "\n",
    "time_sequence_start = datetime.datetime.now()\n",
    "\n",
    "print(\"Timestamp for saved files: {}\".format(save_timestamp))\n",
    "print(\"\\nTraining parameters\")\n",
    "print(\"Number of epochs:    {}\".format(num_epochs))\n",
    "print(\"Step size maximum:   {}\".format(max_learning_rate))\n",
    "print(\"Step size decay:     {}\".format(learning_rate_decay))\n",
    "print(\"Batch size:          {}\".format(batch_size))\n",
    "print(\"Regularization rate: {}\".format(regularization_rate))\n",
    "print(\"\")\n",
    "print(\"Saving validation predictions in: {}\".format(val_data_fullpath))\n",
    "print(\"Saving models in:                 {}\".format(models_save_fullpath))\n",
    "\n",
    "# ROC data will be saved in these containers\n",
    "\n",
    "val_best_metrics    = dict()\n",
    "val_fuzzy_metrics   = dict()\n",
    "val_aurocs          = np.zeros(num_validation_rounds)\n",
    "val_best_thresholds = np.zeros(num_validation_rounds)\n",
    "\n",
    "# Initialize metrics\n",
    "\n",
    "train_loss = 0.0\n",
    "val_loss = 0.0\n",
    "val_dice = 0.0\n",
    "\n",
    "# Perform validation rounds\n",
    "\n",
    "for i in range(num_validation_rounds):\n",
    "    \n",
    "    f = IntProgress(min=0, max=num_epochs)\n",
    "     \n",
    "    # Set Up TensorBoard\n",
    "    \n",
    "    writer = SummaryWriter(f'rect_kernel_runs/{save_timestamp}_validation_round_{i}')\n",
    "    \n",
    "#   Prepare data arrays\n",
    "#   leave out ultrasound_arrays[i]\n",
    "    \n",
    "    train_ultrasound_data = torch.zeros(\n",
    "        [0, ultrasound_tensors[0].shape[1], ultrasound_tensors[0].shape[2], ultrasound_tensors[0].shape[3]]).float()\n",
    "    train_segmentation_data = torch.zeros(\n",
    "        [0, ultrasound_tensors[0].shape[1], ultrasound_tensors[0].shape[2], ultrasound_tensors[0].shape[3]]).long()\n",
    "    \n",
    "    val_ultrasound_data = ultrasound_tensors[i]\n",
    "    val_segmentation_data = segmentation_tensors[i]\n",
    "    val_ultrasound_filename = training_ultrasound_filenames[i]\n",
    "    \n",
    "    for train_index in range(n_files):\n",
    "        if train_index != i:\n",
    "            train_ultrasound_data = torch.cat((train_ultrasound_data, ultrasound_tensors[train_index]))\n",
    "            train_segmentation_data = torch.cat((train_segmentation_data, segmentation_tensors[train_index]))\n",
    "    \n",
    "    n_train = train_ultrasound_data.size(0)\n",
    "    n_val = val_ultrasound_data.size(0)\n",
    "    \n",
    "    print(\"\\n*** Leave-one-out round # {}\".format(i))\n",
    "    print(\"\\nTraining on {} images, validating on {} images...\".format(n_train, n_val))\n",
    "    \n",
    "    display(f)\n",
    "    \n",
    "    # Create and train model\n",
    "\n",
    "    model = UNet_rect_kernels(128,num_classes).to(device).train()\n",
    "    optim = torch.optim.Adam(model.parameters(), lr=max_learning_rate)\n",
    "    lr_scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer=optim, gamma=learning_rate_decay)\n",
    "    criterion = torch.nn.CrossEntropyLoss(weight=torch.tensor(WCE_weights).float()).to(device)\n",
    "    dice_metric = torchmetrics.F1(num_classes=num_classes, mdmc_average='global').to(device).eval()\n",
    "    softmax = torch.nn.Softmax(dim=1).to(device)\n",
    "    \n",
    "    # PyTorch Datasets and DataLoaders\n",
    "    \n",
    "    training_dataset = DataAugmentor(train_ultrasound_data,\n",
    "                                     train_segmentation_data,\n",
    "                                     image_dimensions=(ultrasound_size, ultrasound_size),\n",
    "                                     max_rotation_angle=max_rotation_angle,\n",
    "                                     max_shift_factor=max_shift_factor,\n",
    "                                     min_zoom_factor=min_zoom_factor,\n",
    "                                     max_zoom_factor=max_zoom_factor)\n",
    "    training_generator = torch.utils.data.DataLoader(training_dataset, batch_size=batch_size, num_workers=4)\n",
    "    \n",
    "    val_dataset = DataAugmentor(val_ultrasound_data,\n",
    "                                val_segmentation_data,\n",
    "                                image_dimensions=(ultrasound_size, ultrasound_size),\n",
    "                                max_rotation_angle=max_rotation_angle,\n",
    "                                max_shift_factor=max_shift_factor,\n",
    "                                min_zoom_factor=min_zoom_factor,\n",
    "                                max_zoom_factor=max_zoom_factor)\n",
    "    val_generator = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size, num_workers=4)\n",
    "        \n",
    "    training_time_start = datetime.datetime.now()\n",
    "    \n",
    "    # training loop for this validation split\n",
    "    for epoch in range(1, num_epochs+1):\n",
    "        train_loss = 0.0\n",
    "        val_loss = 0.0\n",
    "        val_dice = 0.0\n",
    "        \n",
    "        # training\n",
    "        model.train()\n",
    "        num = 0\n",
    "        for batch, target in training_generator:\n",
    "            num += 1\n",
    "            optim.zero_grad()\n",
    "            batch = batch.to(device)\n",
    "            target = target.to(device)\n",
    "            pred = model(batch).to(device)\n",
    "            loss = criterion(pred, target.squeeze(1))\n",
    "            loss += regularization_rate * sum(x.abs().sum()for k, x in model.named_parameters() if k.endswith('conv.bias')) * 1e-5\n",
    "            loss.backward()\n",
    "            train_loss += loss.item() * batch.size(0)\n",
    "            optim.step()\n",
    "            \n",
    "        \n",
    "        lr_scheduler.step()\n",
    "        train_loss = train_loss / training_dataset.__len__()\n",
    "        \n",
    "        # validation\n",
    "        model.eval()\n",
    "        num = 0\n",
    "        for batch, target in val_generator:\n",
    "            num += 1\n",
    "            batch = batch.to(device)\n",
    "            target = target.to(device)\n",
    "            with torch.no_grad():\n",
    "                pred = model(batch).to(device)\n",
    "                loss = criterion(pred, target.squeeze(1))\n",
    "                val_loss += loss.item() * batch.size(0)\n",
    "                pred_probmap = softmax(pred)\n",
    "                dice = dice_metric(pred_probmap, target)\n",
    "                val_dice += dice.item()\n",
    "        \n",
    "        if epoch==1:\n",
    "            writer.add_graph(model, batch)\n",
    "            \n",
    "        val_loss = val_loss / val_dataset.__len__()\n",
    "        val_dice = val_dice / num\n",
    "        \n",
    "        writer.add_scalar('Loss/train', train_loss, epoch)\n",
    "        writer.add_scalar('Loss/validation', val_loss, epoch)\n",
    "        writer.add_scalar('Dice/validation', val_dice, epoch)\n",
    "        writer.add_scalar('Meta/learning_rate', lr_scheduler.get_last_lr()[-1], epoch)\n",
    "        \n",
    "        f.value = epoch\n",
    "        \n",
    "\n",
    "    training_time_stop = datetime.datetime.now()\n",
    "    \n",
    "    # Print training log\n",
    "    \n",
    "    print(\"\\nMetrics at the end of training\")\n",
    "    print(\"  val loss:      {}\".format(val_loss))\n",
    "    print(\"  val_dice:      {}\".format(val_dice))\n",
    "    print(\"  Training time: {}\".format(training_time_stop-training_time_start))\n",
    "    \n",
    "    # TODO Plot training loss and metrics\n",
    "    \n",
    "    # Predict on validation data\n",
    "    \n",
    "    y_pred_val  = model(val_ultrasound_data.to(device))\n",
    "    \n",
    "    # Saving predictions for further evaluation\n",
    "    \n",
    "    filename_noext, extension = os.path.splitext(val_ultrasound_filename)\n",
    "    val_prediction_filename = save_timestamp + \"_prediction_\" + filename_noext + \".npy\"\n",
    "    val_prediction_fullname = os.path.join(val_data_fullpath, val_prediction_filename)\n",
    "    torch.save(y_pred_val, val_prediction_fullname)\n",
    "    \n",
    "    # Archive trained model with unique filename based on notebook name and timestamp\n",
    "    \n",
    "    model_file_name = this_notebook_name + \"_model-\" + str(i) + \"_\" + save_timestamp + \".msd\"\n",
    "    model_fullname = os.path.join(models_save_fullpath, model_file_name)\n",
    "    print(model_fullname)\n",
    "    torch.save(model.state_dict(), model_fullname)\n",
    "    \n",
    "    # Validation results\n",
    "     \n",
    "#     vali_metrics_dicts, vali_best_threshold_index, vali_area = evaluation_metrics.compute_roc(\n",
    "#         roc_thresholds, y_pred_val, val_segmentation_data, acceptable_margin_mm, mm_per_pixel)\n",
    "    \n",
    "#     val_fuzzy_metrics[i] = evaluation_metrics.compute_evaluation_metrics(\n",
    "#         y_pred_val, val_segmentation_data, acceptable_margin_mm, mm_per_pixel)\n",
    "    \n",
    "#     val_best_metrics[i]    = vali_metrics_dicts[vali_best_threshold_index]\n",
    "#     val_aurocs[i]          = vali_area\n",
    "#     val_best_thresholds[i] = roc_thresholds[vali_best_threshold_index]\n",
    "    \n",
    "    # Printing total time of this validation round\n",
    "    \n",
    "    print(\"\\nTotal round time:  {}\".format(datetime.datetime.now() - training_time_start))\n",
    "    print(\"\")\n",
    "    \n",
    "    # just do one validation split\n",
    "#     break\n",
    "\n",
    "\n",
    "time_sequence_stop = datetime.datetime.now()\n",
    "\n",
    "print(\"\\nTotal training time:   {}\".format(time_sequence_stop - time_sequence_start))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "require([\"base/js/namespace\"],function(Jupyter) {\n",
       "    Jupyter.notebook.save_checkpoint();\n",
       "});\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save notebook so all output is archived by the next cell\n",
    "\n",
    "from IPython.display import Javascript\n",
    "script = '''\n",
    "require([\"base/js/namespace\"],function(Jupyter) {\n",
    "    Jupyter.notebook.save_checkpoint();\n",
    "});\n",
    "'''\n",
    "Javascript(script)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Notebook saved to: /home/nick/dev/SaggitalSpineSegmentation_Data/SavedNotebooks/PyTorchSagittalSpineSegmentationStudy-RectangularKernels_2021-08-05_16-21-43.html\n"
     ]
    }
   ],
   "source": [
    "# Export HTML copy of this notebook\n",
    "\n",
    "notebook_file_name = this_notebook_name + \"_\" + save_timestamp + \".html\"\n",
    "notebook_fullname = os.path.join(notebooks_save_fullpath, notebook_file_name)\n",
    "\n",
    "os.system(\"jupyter nbconvert --to html \" + this_notebook_name + \" --output \" + notebook_fullname)\n",
    "print(\"Notebook saved to: {}\".format(notebook_fullname))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assert False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([446, 128, 128])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_sm = torch.nn.functional.softmax(y_pred_val, dim=1)\n",
    "pred_sm = pred_sm[:,1,:,:]\n",
    "pred_sm.size()\n",
    "# torch.nn.functional.softmax(y_pred_val, dim=1)[:,1,:,:].to('cpu').detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_sm_np = np.array(pred_sm.to('cpu').detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_np = torch.squeeze(val_segmentation_data, dim=1).detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x1080 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "index = int(523*np.random.rand())\n",
    "\n",
    "fig, axs = plt.subplots(1,2)\n",
    "fig.set_size_inches(20,15)\n",
    "axs[0].imshow(gt_np[index])\n",
    "axs[1].imshow(pred_sm_np[index])\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#blah#blah\n",
    "#blah#blah\n",
    "#blah#blah#blah#blah\n",
    "#blah#blah\n",
    "#blah#blah#blah#blah\n",
    "#blah#blah\n",
    "#blah#blah#blah#blah\n",
    "#blah#blah\n",
    "#blah#blah#blah#blah\n",
    "#blah#blah\n",
    "#blah#blah#blah#blah\n",
    "#blah#blah\n",
    "#blah#blah#blah#blah\n",
    "#blah#blah\n",
    "#blah#blah#blah#blah\n",
    "#blah#blah\n",
    "#blah#blah#blah#blah\n",
    "#blah#blah\n",
    "#blah#blah#blah#blah\n",
    "#blah#blah\n",
    "#blah#blah#blah#blah\n",
    "#blah#blah\n",
    "#blah#blah#blah#blah\n",
    "#blah#blah\n",
    "#blah#blah#blah#blah\n",
    "#blah#blah\n",
    "#blah#blah"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
